[[intro-reactive]]
= Введение в Реактивное программирование
Reactor is an implementation of the Reactive Programming paradigm, which can be summed up
as:

[quote, https://ru.wikipedia.org/wiki/Реактивное_программирование]
Реактивное программирование — парадигма программирования, ориентированная на потоки данных и распространение изменений. Это означает, что должна существовать возможность легко выражать статические и динамические потоки данных, а также то, что нижележащая модель исполнения должна автоматически распространять изменения благодаря потоку данных.

As a first step in the direction of reactive programming, Microsoft created the Reactive
Extensions (Rx) library in the .NET ecosystem. Then RxJava implemented reactive
programming on the JVM.  As time went on, a standardization for Java emerged through the
*Reactive Streams* effort, a specification that defines a set of interfaces and
interaction rules for reactive libraries on the JVM. Its interfaces have been
integrated into Java 9 under the parent `Flow` class.

Парадигма реактивного программирования в обьектно ориентированных языках часто представляется как расширение
паттерная Observer. Так же можно сравнить реактивные потоки (stream) с хорошо всем знакомым паттерном Iterator.
Связка `Iterable`-`Iterator` есть во всех библиотеках. Основное отличие в том что  Iterator основан на  *pull*-модели,
а реактивные потоки использую *push*-подход.

Iterator - шаблон имеративного программирования. Ответственность за метод доступа к значениям лежит исключительно на `Iterable`.
Разработчик сам выбирает когда получить доступ к элементу последовательности вызвав метод `next()`.
В реактивных потоках, эквивалент вышеупомянутой связки `Publisher-Subscriber`.
Разница в том, что  `Publisher` уведомляет `Subscriber` о новых доступных значениях _по мере их поступления_,
и это уведомление(push) является сигналом к действиям.Кроме того, операции, применяемые к опубликованным значениям,
описываются в декларативном стиле, а не императивно: программист описывает логику вычислений,
а не описывает набор инструкций для последовательного выполнения.


В дополнение к push модели, кроме публикации значений, реактиное программирование четко описывает способы обработы ошибок
и завершения потоков.`Publisher` может выдвигать новые значения в его `Subscriber` (вызывая метод `onNext`),
может сигнализировать об ошибке (вызывая метод `onError`) или завершении (вызывая метод `onComplete`).
И ошибки и сигнал завершения  завершают последовательность. Это можно представить как:

[source]
onNext x 0..N [onError | onComplete]

Такой подход очень гибкий. Шаблон описывает случаи использования где нет значений,
есть одно значение или есть n значений (включая бесконечную последовательность значений, к примеру тики часов).

Но вначале давайте рассмотрим зачем нам вообще нужна такая асинхронная реактивная библиотека?

== Блокировки могут быть расточительны
Современные приложения могут обслуживатель большое количество пользователей одновременно,
и несмотря на то что аппаратное обеспечение, продолжает улучшаться, производительность современного
ПО по прежнему являвется ключевой проблемой.

Существует два основных способа увеличения производительности программы:

. *распаралелить*: использовать больше потоков и больше аппаратных ресурсов.
. *стремится к большей эффективности* в использовании имебщихся аппаратных ресурсов.

Обычно Java разработчики пишут используя блокирующий код. Этот подход хорош, пока не возникнет узкое место
в производительности программы, после этого приходится запускать дополнительные потоки,
выполнябщие аналогичный блокируемый код. Но такой подход к масштабированию обычно быстро вызывает
проблемы конкуретного доступа.

Еще хуже,что это вызовет блокировку ненужных ресурсов. Обратите внимание, как тольпо программа предполагает
работу с задержкой (особенно операции ввода/вывода, такие как запросы к БД или сетевое взаимодействие),
ресурсы тратятся зря, потому что поток (или несколько потоков) простаивает без работы,
находясь в состоянии ожидания данных.

Поэтому подход к распаралеливанию не является серебрянной пулей. Конечно, он хорошо подходит чтобы использовать все
доступные аппаратные ресурсы, но он также приводит к их неэффективному использованию.

== Асинхронность спасет нас?
Второй подход (из упомянутых ранее), в повышении эффективности, может стать решением проблемы расточительного
использования ресурсов. Написав _асинхронный_, _неблокируемый_код_,
вы позволите исполнителю переключатся на другую активную задачу *спользуя те же основные ресурсы*,
а затем вернутся к текущей задаче, когда асинхронная обработка другой завершится.

Какие есть способы написани асинхронного кода под JVM? Java предоставляет две модели асинхронного программирования:

* *Callbacks*: Асинхронные методы не возвращают значение, но принимают дополнительный парамер
`callback`(лямбда выражение или аноанимный класс) котоый вызывается, когда результат готов.
Врем известным примером является `EventListener` из библиотеки  Swing.
* *Futures*: Асинхроанные методы возвращают обьет `Future<T>` *немедленно*. Асинхронный процесс вычисляет
занчение `T`, а обьект `Future` является обверткой, для доступа к нему. Значение доступно не сразу, и обьект Future
можно опрашивать, пока значение не станет доступным. Например при использовании `ExecutorService` запуск `Callable<T>`
возвращает `Future` обьекты.

Что не так с этими методами? Каждый из них имеет свои ограничения в большинстве вариантов использования.

Композиция Callback'ов очень трудное занятие, написание такого кода быстро приводит
к результату который трудно читать и поддерживать.(известный всем "Callback Hell").

Рассмотрим пример: показать прять избранных обьектов в пользовательском интерфейсе или показать рекомендации, если
у пользователя нет избранных обьектов.
Для этого используются три сервиса(один возвращает IDs избранных обьектов,
второй получает обьекты, а третий получает обьекты предложений):

.Пример  Callback Hell
[source,java]
----
userService.getFavorites(userId, new Callback<List<String>>() { //<1>
  public void onSuccess(List<String> list) { //<2>
    if (list.isEmpty()) { //<3>
      suggestionService.getSuggestions(new Callback<List<Favorite>>() {
        public void onSuccess(List<Favorite> list) { //<4>
          UiUtils.submitOnUiThread(() -> { //<5>
            list.stream()
                .limit(5)
                .forEach(uiList::show); //<6>
            });
        }

        public void onError(Throwable error) { //<7>
          UiUtils.errorPopup(error);
        }
      });
    } else {
      list.stream() //<8>
          .limit(5)
          .forEach(favId -> favoriteService.getDetails(favId, //<9>
            new Callback<Favorite>() {
              public void onSuccess(Favorite details) {
                UiUtils.submitOnUiThread(() -> uiList.show(details));
              }

              public void onError(Throwable error) {
                UiUtils.errorPopup(error);
              }
            }
          ));
    }
  }

  public void onError(Throwable error) {
    UiUtils.errorPopup(error);
  }
});
----
<1> У нас есть сервисы, доступ к которым основан на callback: a `Callback` интерфейс с методамми,
которые вызываются в случае успеха или ошибки
<2> Первый сервис вызывает callback со списком  ID избранных обьектов.
<3> Если список пусты, мы переходим к `suggestionService`.
<4> `suggestionService` возвращает `List<Favorite>` во второй callback.
<5> Так как мы работаем с пользовательским интерфесом, мы должны гарантированно запустить код в потоке интерфейса.
<6> Мы используем Java 8 `Stream` что бы ограничить результат 5 элементами, и  передаем их в пользовательский интерфейс.
<7> На каждом уровне мы одинаково обрабатываем ошибки: показыаем их во всплывающем окне.
<8> Вернемся к ID избаррных элементов. Если сервис вернул список id, нам нужно получить полные обьекты
из `favoriteService`. Так как мы хотим только 5 элементов, мы ограничим поток ID 5 элементами.
<9> Еще один callback. На этот раз мы получаем полные обьекты `Favorite`, которые мы отображаем в пользовательском
интерфейсе внутри потока пользовательского интерфейса.

Мы написали много кода, его трудно читать и в нем есть повторяющиеся части.
Рассмотрим аналогичный код с использованием Reactor:

.Пример кода с использованием Reactor, функционально аналогичный примеру выше
[source,java]
----
userService.getFavorites(userId) // <1>
           .flatMap(favoriteService::getDetails) // <2>
           .switchIfEmpty(suggestionService.getSuggestions()) // <3>
           .take(5) // <4>
           .publishOn(UiUtils.uiThreadScheduler()) // <5>
           .subscribe(uiList::show, UiUtils::errorPopup); // <6>
----
<1> Мы начинаем с получения потока  ID избранных.
<2> Мы _асинхронно преобразуем_ их в полные обьекты `Favorite` (`flatMap`).
Теперь у нас поток обьектов `Favorite`.
<3> В случае если поток обьектов `Favorite` пустой, мы переключаемся на запасной поток от
`suggestionService`.
<4> Нас интересует не более 5 элементов из полученного потока.
<5> В конце мы хотим обработать каждый элемент в потоке пользовательского интерфейса.
<6> Мы запускаем поток(flow, не thread), описывая что делать с окончательной формой данных
(показывать ее в UI) и что делать в случае ошибки (показывать всплывающее окно).

What if you want to ensure the favorite IDs are retrieved in less than 800ms or, if it
takes longer, get them from a cache? In the callback-based code, that is a complicated
task. In Reactor it becomes as easy as adding a `timeout` operator in the chain:

.Example of Reactor code with timeout and fallback
[source,java]
----
userService.getFavorites(userId)
           .timeout(Duration.ofMillis(800)) // <1>
           .onErrorResume(cacheService.cachedFavoritesFor(userId)) // <2>
           .flatMap(favoriteService::getDetails) // <3>
           .switchIfEmpty(suggestionService.getSuggestions())
           .take(5)
           .publishOn(UiUtils.uiThreadScheduler())
           .subscribe(uiList::show, UiUtils::errorPopup);
----
<1> If the part above emits nothing for more than 800ms, propagate an error.
<2> In case of an error, fall back to the `cacheService`.
<3> The rest of the chain is similar to the previous example.

Futures are a bit better than callbacks, but they still do not do well at composition,
despite the improvements brought in Java 8 by `CompletableFuture`. Orchestrating multiple
futures together is doable but not easy. Also, `Future` has other problems: It is easy to
end up with another blocking situation with `Future` objects by calling the `get()`
method, they do not support lazy computation and they lack support for multiple
values and advanced error handling.

Consider another example: We get a list of IDs from which we want to fetch a name and a
statistic and combine these pair-wise, all of it asynchronously.

.Example of `CompletableFuture` combination
[source,java]
----
CompletableFuture<List<String>> ids = ifhIds(); // <1>

CompletableFuture<List<String>> result = ids.thenComposeAsync(l -> { // <2>
	Stream<CompletableFuture<String>> zip =
			l.stream().map(i -> { // <3>
				CompletableFuture<String> nameTask = ifhName(i); // <4>
				CompletableFuture<Integer> statTask = ifhStat(i); // <5>

				return nameTask.thenCombineAsync(statTask, (name, stat) -> "Name " + name + " has stats " + stat); // <6>
			});
	List<CompletableFuture<String>> combinationList = zip.collect(Collectors.toList()); // <7>
	CompletableFuture<String>[] combinationArray = combinationList.toArray(new CompletableFuture[combinationList.size()]);

	CompletableFuture<Void> allDone = CompletableFuture.allOf(combinationArray); // <8>
	return allDone.thenApply(v -> combinationList.stream()
			.map(CompletableFuture::join) // <9>
			.collect(Collectors.toList()));
});

List<String> results = result.join(); // <10>
assertThat(results).contains(
		"Name NameJoe has stats 103",
		"Name NameBart has stats 104",
		"Name NameHenry has stats 105",
		"Name NameNicole has stats 106",
		"Name NameABSLAJNFOAJNFOANFANSF has stats 121");
----
<1> We start off with a future that gives us a list of `id` values to process.
<2> We want to start some deeper asynchronous processing once we get the list.
<3> For each element in the list:
<4> Asynchronously get the associated name.
<5> Asynchronously get the associated task.
<6> Combine both results.
<7> We now have a list of futures that represent all the combination tasks. In order to
execute these tasks, we need to convert the list to an array.
<8> Pass the array to `CompletableFuture.allOf`, which outputs a `Future` that completes
when all tasks have completed.
<9> The tricky bit is that `allOf` returns `CompletableFuture<Void>`, so we
reiterate over the list of futures, collecting their results via `join()`
(which here doesn't block since `allOf` ensures the futures are all done).
<10> Once the whole asynchronous pipeline has been triggered, we wait for it to
be processed and return the list of results that we can assert.

Since Reactor has more combination operators out of the box, this process can be
simplified:

.Example of Reactor code equivalent to future code
[source,java]
----
Flux<String> ids = ifhrIds(); // <1>

Flux<String> combinations =
		ids.flatMap(id -> { // <2>
			Mono<String> nameTask = ifhrName(id); // <3>
			Mono<Integer> statTask = ifhrStat(id); // <4>

			return nameTask.zipWith(statTask, // <5>
					(name, stat) -> "Name " + name + " has stats " + stat);
		});

Mono<List<String>> result = combinations.collectList(); // <6>

List<String> results = result.block(); // <7>
assertThat(results).containsExactly( // <8>
		"Name NameJoe has stats 103",
		"Name NameBart has stats 104",
		"Name NameHenry has stats 105",
		"Name NameNicole has stats 106",
		"Name NameABSLAJNFOAJNFOANFANSF has stats 121"
);
----
<1> This time, we start from an asynchronously provided sequence of `ids` (a
`Flux<String>`).
<2> For each element in the sequence, we asynchronously process it (inside the function
that is the body `flatMap` call) twice.
<3> Get the associated name.
<4> Get the associated statistic.
<5> Asynchronously combine the 2 values.
<6> Aggregate the values into a `List` as they become available.
<7> In production, we would continue working with the `Flux` asynchronously by further
combining it or subscribing to it. Most probably, we would return the `result` `Mono`.
Since we are in a test, we block, waiting for the processing to finish instead, and then
directly return the aggregated list of values.
<8> Assert the result.

These perils of Callback and Future are similar and are what reactive programming
addresses with the `Publisher-Subscriber` pair.

== From Imperative to Reactive Programming
Reactive libraries such as Reactor aim to address these drawbacks of "classic"
asynchronous approaches on the JVM while also focusing on a few additional aspects:

* *Composability* and *readability*
* Data as a *flow* manipulated with a rich vocabulary of *operators*
* Nothing happens until you *subscribe*
* *Backpressure* or _the ability for the consumer to signal the producer that the rate of
emission is too high_
* *High level* but *high value* abstraction that is _concurrency-agnostic_

=== Composability and Readability
By composability, we mean the ability to orchestrate multiple asynchronous tasks, using
results from previous tasks to feed input to subsequent ones or executing several tasks
in a fork-join style, as well as reusing asynchronous tasks as discrete components in a
higher-level system.

The ability to orchestrate tasks is tightly coupled to the readability and
maintainability of code. As the layers of asynchronous processes increase in both number
and complexity, being able to compose and read code becomes increasingly difficult. As we
saw, the callback model is simple, but one of its main drawbacks is that, for complex
processes, you need to have a callback executed from a callback, itself nested inside
another callback, and so on. That mess is known as *Callback Hell*. As you can guess (or
know from experience), such code is pretty hard to go back to and reason about.

Reactor offers rich composition options, wherein code mirrors the organization of the
abstract process, and everything is generally kept at the same level (nesting is
minimized).

=== The Assembly Line Analogy
You can think of data processed by a reactive application as moving through an assembly
line. Reactor is both the conveyor belt and the workstations. The raw material pours from
a source (the original `Publisher`) and ends up as a finished product ready to be pushed
to the consumer (or `Subscriber`).

The raw material can go through various transformations and other intermediary steps or
be part of a larger assembly line that aggregates intermediate pieces together. If there
is a glitch or clogging at one point (perhaps boxing the products takes a
disproportionately long time), the afflicted workstation can signal upstream to limit the
flow of raw material.

=== Operators
In Reactor, operators are the workstations in our assembly analogy. Each operator adds
behavior to a `Publisher` and wraps the previous step's `Publisher` into a new instance.
The whole chain is thus linked, such that data originates from the first `Publisher` and
moves down the chain, transformed by each link. Eventually, a `Subscriber` finishes the
process. Remember that nothing happens until a `Subscriber` subscribes to a `Publisher`,
as we see shortly.

TIP: Understanding that operators create new instances can help you avoid a common
mistake that would lead you to believe that an operator you used in your chain is not
being applied. See this <<faq.chain,item>> in the FAQ.

While the Reactive Streams specification does not specify operators at all, one of the
best added values of reactive libraries such as Reactor is the rich vocabulary of
operators  that they provide. These cover a lot of ground, from simple transformation and
filtering to complex orchestration and error handling.

[[reactive.subscribe]]
=== Nothing Happens Until You `subscribe()`
In Reactor, when you write a `Publisher` chain, data does not start pumping into it by
default. Instead, you create an abstract description of your asynchronous process (which
can help with reusability and composition).

By the act of *subscribing*, you tie the `Publisher` to a `Subscriber`, which triggers
the flow of data in the whole chain. This is achieved internally by a single `request`
signal from the `Subscriber` that is propagated upstream, all the way back to the source
`Publisher`.

[[reactive.backpressure]]
=== Backpressure
Propagating signals upstream is also used to implement *backpressure*, which we described
in the assembly line analogy as a feedback signal sent up the line when a workstation
processes more slowly than an upstream workstation.

The real mechanism defined by the Reactive Streams specification is pretty close to the
analogy: a subscriber can work in _unbounded_ mode and let the source push all the data
at its fastest achievable rate or it can use the `request` mechanism to signal the source
that it is ready to process at most `n` elements.

Intermediate operators can also change the request in-transit. Imagine a `buffer`
operator that groups elements in batches of 10. If the subscriber requests 1 buffer, it
is acceptable for the source to produce 10 elements. Some operators also implement
**prefetching** strategies, which avoids `request(1)` round-trips and is beneficial
if producing the elements before they are requested is not too costly.

This transforms the push model into a **push-pull hybrid** where the downstream can pull n
elements from upstream if they are readily available. But if the elements are not ready,
they get pushed by the upstream whenever they are produced.

[[reactive.hotCold]]
=== Hot vs Cold
In the Rx family of reactive libraries, one can distinguish two broad categories of
reactive sequences: *hot* and *cold*. This distinction mainly has to do with how the
reactive stream reacts to subscribers:

- A *Cold* sequence starts anew for each `Subscriber`, including at the source of data.
For example if the source wraps an HTTP call, a new HTTP request is made for each subscription.
- A *Hot* sequence does not start from scratch for each `Subscriber`. Rather, late
subscribers receive signals emitted _after_ they subscribed. Note, however, that some hot
reactive streams can cache or replay the history of emissions totally or partially. From
a general perspective, a hot sequence can even emit when no subscriber is listening (an
exception to the "nothing happens before you subscribe" rule).

For more information on hot vs cold in the context of Reactor, see
<<reactor.hotCold,this reactor-specific section>>.

//TODO talk about concurrency agnostic? elements of functional style?
